{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38275ca5",
   "metadata": {},
   "source": [
    "# COMP0078 Supervised Learning - Coursework 1 {-}\n",
    "\n",
    "### Student ID: 18006555  {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d638aaa",
   "metadata": {},
   "source": [
    "## Part I [20%]  {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11450fef",
   "metadata": {},
   "source": [
    "### Rademacher Complexity of finite Spaces {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d84800",
   "metadata": {},
   "source": [
    "We start with $X_1, \\cdots, X_m$ of centered random variables $\\left(E[X_i] = 0\\right)$, taking values in $[a,b]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f0e89d",
   "metadata": {},
   "source": [
    "### 1.1 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf07c5",
   "metadata": {},
   "source": [
    "We let $\\bar{X} = \\max_i X_i$. For $\\lambda > 0$, we aim to show:\n",
    "\n",
    "$$E[\\bar{X}] \\leq \\frac{1}{\\lambda}log E[e^{\\lambda \\bar{X}}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a81a30",
   "metadata": {},
   "source": [
    "We use Jensen's inequality i.e. if $g$ is a convex function and $X$ is a random variable, then $g(E[X]) \\leq E[g(X)]$.\n",
    "\n",
    "Since $g(x) = e^{\\lambda x}$ is a convex function for $\\lambda > 0$, we note that:\n",
    "\n",
    "$$e^{\\lambda E[\\bar{X}]} \\leq E[e^{\\lambda\\bar{X}}]$$\n",
    "$$\\lambda E[\\bar{X}] \\leq \\log E[e^{\\lambda\\bar{X}}]$$\n",
    "$$E[\\bar{X}] \\leq \\frac{1}{\\lambda} \\log E[e^{\\lambda\\bar{X}}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0d2f8",
   "metadata": {},
   "source": [
    "### 1.2 {-}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a980e0",
   "metadata": {},
   "source": [
    "We now aim to show:\n",
    "\n",
    "$$\\frac{1}{\\lambda}\\log E[e^{\\lambda \\bar{X}}] \\leq \\frac{1}{\\lambda} \\log m + \\lambda \\frac{(b-a)^2}{8}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a10c1d",
   "metadata": {},
   "source": [
    "We use Hoeffding's Lemma which states that for any random variable $X$ such that $X - E[X] \\in [a,b]$ and $\\lambda > 0$, we have:\n",
    "\n",
    "$$E[e^{\\lambda(X-E[X])}] \\leq e^{\\frac{1}{8}\\lambda^2 (b-a)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c222e4",
   "metadata": {},
   "source": [
    "If we choose $X_i$ as our random variable, this satisfies our conditions for Hoeffding's Lemma since $X_i - E[X_i] \\in [a,b]$ since $E[X_i] = 0$. We then apply the Lemma over a summation of the $X_i$ s from 1 to $m$:\n",
    "\n",
    "\\begin{align*}\n",
    "E[e^{\\lambda(X_i-E[X_i])}] &\\leq e^{\\frac{1}{8}\\lambda^2 (b-a)^2}\\\\\n",
    "\\sum_{i=1}^m E[e^{\\lambda(X_i)}] &\\leq \\sum_{i=1}^m e^{\\frac{1}{8}\\lambda^2 (b-a)^2}\\\\\n",
    "E[e^{\\lambda \\bar{X}}] \\leq \\sum_{i=1}^m E[e^{\\lambda(X_i)}] &\\leq m \\times e^{\\frac{1}{8}\\lambda^2 (b-a)^2}\\\\\n",
    "\\frac{1}{\\lambda} \\log E[e^{\\lambda \\bar{X}}] &\\leq  \\frac{1}{\\lambda} \\log m + \\frac{1}{\\lambda} \\log e^{\\frac{1}{8}\\lambda^2 (b-a)^2}\\\\\n",
    "\\frac{1}{\\lambda} \\log E[e^{\\lambda \\bar{X}}] &\\leq  \\frac{1}{\\lambda} \\log m + \\frac{1}{8}\\lambda (b-a)^2\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11975f1b",
   "metadata": {},
   "source": [
    "### 1.3 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8ebbd",
   "metadata": {},
   "source": [
    "Now we combine the previous two inequality results, and choose $\\lambda = \\sqrt{\\frac{8\\log m}{(b-a)^2}}$, to conclude with:\n",
    "\n",
    "\\begin{align*}\n",
    "E[\\bar{X}] &\\leq \\frac{1}{\\lambda} \\log m + \\frac{1}{8}\\lambda (b-a)^2 \\\\\n",
    "E[\\bar{X}] &\\leq \\sqrt{\\frac{(b-a)^2}{8\\log m}} \\log m + \\frac{1}{8} \\sqrt{\\frac{8\\log m}{(b-a)^2}} (b-a)^2 \\\\\n",
    "E[\\bar{X}] &\\leq \\sqrt{\\frac{1}{8}(b-a)^2\\log m} + \\sqrt{\\frac{1}{8}(b-a)^2\\log m} \\\\\n",
    "E[\\bar{X}] &\\leq 2\\sqrt{\\frac{1}{8}(b-a)^2\\log m}\\\\\n",
    "E[\\max_{i=1,\\cdots,m} X_i] &\\leq \\frac{b-a}{2}\\sqrt{2\\log m}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a2a0d",
   "metadata": {},
   "source": [
    "### 1.4 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b88ca90",
   "metadata": {},
   "source": [
    "We now provide the bound for the Rademacher complexity of a finite set of hypotheses. For each point $x \\in S$, $\\frac{1}{n} \\sum_{j=1}^n \\sigma_j x_j$ is a sum of independent random variables, which are centered because Rademacher variables $\\sigma_j$ have zero mean, as they are equally likely to be -1 or 1. Therefore each term $\\sigma_j x_j$ is either $-|x_j|$ or $|x_j|$, and hence the range is $2|x_j|$.\n",
    "\n",
    "We have already showed that for centered random variables $X_i$ which are bounded by $[a,b]$, that $E[\\max_i X_i] \\leq \\frac{b-a}{2}\\sqrt{2\\log m}$, where $b-a = 2|x_j|$ for each term in the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41b6a1e",
   "metadata": {},
   "source": [
    "Now we continue as:\n",
    "\n",
    "$$R(S) = E_{\\sigma} \\max_{x \\in S} \\frac{1}{n} \\sum_{j=1}^n\\sigma_j x_j \\leq \\max_{x \\in S} \\frac{1}{n} \\sum_{j=1}^n |x_j| \\sqrt{2\\log m} = \\max_{x \\in S} ||x||_2 \\frac{\\sqrt{2\\log m}}{n}$$\n",
    "$$R(S) < \\max_{x \\in S} ||x||_2 \\frac{\\sqrt{2\\log m}}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd0569",
   "metadata": {},
   "source": [
    "### 1.5 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9bbf04",
   "metadata": {},
   "source": [
    "We start with the definition for the empirical Rademacher complexity $R_S(H)$, where $H$ is a set of hypotheses, and has finite cardinality $|H| < + \\infty$. We can use the previous sections to prove an upper bound for $R_S(H)$, where $|H|$ appears logarithmically:\n",
    "\n",
    "$$ R_S(H) = E_{σ} \\left[sup_{f \\in H} \\frac{1}{n} \\sum_{i=1}^{n} σ_i \\cdot f(x_i)\\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d9fcc",
   "metadata": {},
   "source": [
    "Now we consider each hypothesis $f \\in H$ as a vector in $R^n$, defined by its evaluations on the set of points $S = (x_i)_{i=1}^n$ i.e. we write $f_S = (f(x_i))_{i=1}^n$. $f_S$ is also just a set of points like $S$, hence we can apply the result from 1.4 on $f_S$:\n",
    "\n",
    "$$R(f_S) \\leq \\max_{f \\in H} ||f_S||_2 \\frac{\\sqrt{2\\log m}}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b403b",
   "metadata": {},
   "source": [
    "The empirical Rademacher complexity for the hypothesis set H is the expectation of the supremum over all such bounds for individual hypotheses $f$ i.e. we are looking for the 'worst-case' for the bound across all hypotheses in $H$. Hence:\n",
    "$$R_S(H) \\leq \\frac{M}{n}\\sqrt{2\\log{m}}$$\n",
    "Where $M = \\max_{f \\in H} ||f_S||_2$ i.e. $\\forall f \\in H, ||f_S||_2 \\leq M$.\n",
    "Since we are now dealing with a set of hypotheses $H$, and the empirical Rademache complexity $R_S(H)$ now represents a measure of complexity of $H$, and depends on how many different hypotheses $f$ wer are considering i.e. $|H|$, as opposed to 1.4 where we were considering the complexity of the set of points $S$, determined by $|S| = m$. Hence we finish with the upper bound for $R_S(H)$ as follows:\n",
    "$$R_S(H) \\leq \\frac{M}{n}\\sqrt{2\\log{|H|}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbaa13",
   "metadata": {},
   "source": [
    "## Part II [40%] {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986b649",
   "metadata": {},
   "source": [
    "### Bayes Decision Rule and Surrogate Approaches {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3abb268",
   "metadata": {},
   "source": [
    "### 2.1 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3522a0fa",
   "metadata": {},
   "source": [
    "We start with the misclassification error of a classification rule $c(x)$, defined as follows:\n",
    "\n",
    "$$R(c) = P_{(x,y)\\sim \\rho}(c(x) \\neq y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08fe12a",
   "metadata": {},
   "source": [
    "Since the probability of an event occurring is equal to the expected value of its corresponding indicator function, we can write $R(c)$ as follows:\n",
    "\n",
    "$$R(c) = E_{(x,y)\\sim \\rho}[1_{c(x)\\neq y}]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab77b15",
   "metadata": {},
   "source": [
    "Now using the definition of Expectation, we can expand as follows:\n",
    "\n",
    "$$R(c) = \\int_{X \\times Y} 1_{c(x)\\neq y} d\\rho(x,y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6cc6cc",
   "metadata": {},
   "source": [
    "This integral effectively sums the occurrences where $c(x) \\neq y$ i.e. the misclassifications, which in turn will correspond to the average number of misclassifications (as a proportion of the total input-output pairs $(x,y)$) and hence represents the misclassification error $R(c)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990969b7",
   "metadata": {},
   "source": [
    "### 2.2 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d26d467",
   "metadata": {},
   "source": [
    "We now solve Surrogate Approaches for different loss functions, calculating the closed-form of the minimiser $f_*$ of $\\epsilon(f)$ defined as:\n",
    "\n",
    "$$\\epsilon(f) = \\int_{X \\times Y} l(f(x),y) d\\rho(x,y) = \\int_X \\left( \\int_Y l(f(x),y) d\\rho(y|x) \\right) d\\rho_X(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5877bf6f",
   "metadata": {},
   "source": [
    "We now consider the problem in the inner integral point-wise $\\forall x \\in X$, differentiating with respect to $f$ and setting equal to zero:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial f} \\int_Y l(f(x),y) d\\rho(y|x) = 0$$\n",
    "$$\\int_Y \\frac{\\partial l(f(x),y)}{\\partial f} d\\rho(y|x) = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160109c5",
   "metadata": {},
   "source": [
    "#### 2.2 part a) {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756813e",
   "metadata": {},
   "source": [
    "Squared Loss: $l(f(x),y) = (f(x)-y)^2$\n",
    "\n",
    "\\begin{align*}\n",
    "0 &= \\int_Y \\frac{\\partial l(f(x),y)}{\\partial f} d\\rho(y|x) \\\\\n",
    "0 &= \\int_Y \\frac{\\partial (f(x)-y)^2)}{\\partial f} d\\rho(y|x) \\\\\n",
    "0 &= \\int_Y 2(f(x)-y) d\\rho(y|x) \\\\\n",
    "f(x) &= \\int_Y y d\\rho(y|x) \\\\\n",
    "f(x) &= (1)\\rho(y=1|x) + (-1)\\rho(y=-1|x) \\\\\n",
    "f_*(x) &= 2\\rho(y=1|x) - 1 \\hspace{1em} (= E[y|x])\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c989e1c",
   "metadata": {},
   "source": [
    "### 2.2 part b) {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6a2fa",
   "metadata": {},
   "source": [
    "Exponential loss: $l(f(x),y) = \\exp(-yf(x))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f2a18d",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "0 &= \\int_Y \\frac{\\partial l(f(x),y)}{\\partial f} d\\rho(y|x) \\\\\n",
    "0 &= \\int_Y \\frac{\\partial \\exp(-yf(x))}{\\partial f} d\\rho(y|x) \\\\\n",
    "0 &= \\int_Y -y\\exp(-yf(x)) d\\rho(y|x) \\\\\n",
    "0 &= -\\exp(-f(x))\\rho(y=1|x) + \\exp(f(x))\\rho(y=-1|x) \\\\\n",
    "\\exp(-f(x))\\rho(y=1|x) &= \\exp(f(x))\\rho(y=-1|x) \\\\\n",
    "\\exp(f_*(x))^2 &= \\frac{\\rho(y=1|x)}{\\rho(y=-1|x)} \\\\\n",
    "f_*(x) &= \\frac{1}{2}\\log{\\left(\\frac{\\rho(y=1|x)}{1-\\rho(y=1|x)}\\right)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4084e1bb",
   "metadata": {},
   "source": [
    "### 2.2 part c) {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea6d769",
   "metadata": {},
   "source": [
    "Logistic loss: $l(f(x),y) = \\log(1+\\exp(-yf(x)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304957ae",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "0 &= \\int_Y \\frac{\\partial l(f(x),y)}{\\partial f} d\\rho(y|x) \\\\\n",
    "0 &= \\int_Y \\frac{\\partial \\log(1+\\exp(-yf(x)))}{\\partial f} d\\rho(y|x) \\\\\n",
    "0 &= \\int_Y \\frac{-y}{1+\\exp(yf(x))} d\\rho(y|x) \\\\\n",
    "0 &= \\frac{-1}{1+\\exp(f(x))}\\rho(y=1|x) + \\frac{1}{1+\\exp(-f(x))}\\rho(y=-1|x) \\\\\n",
    "(1+\\exp(-f(x)))\\rho(y=1|x) &= (1+\\exp(f(x))\\rho(y=-1|x)) \\\\\n",
    "\\frac{1+\\exp(f(x))}{\\exp(-f(x))+1} &= \\frac{\\rho(y=1|x)}{1-\\rho(y=1|x)} \\\\\n",
    "\\exp(f(x))&= \\frac{\\rho(y=1|x)}{1-\\rho(y=1|x)} \\\\\n",
    "f_*(x) &= \\log\\left(\\frac{\\rho(y=1|x)}{1-\\rho(y=1|x)}\\right) \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4d567c",
   "metadata": {},
   "source": [
    "### 2.2 part d) {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd4c4aa",
   "metadata": {},
   "source": [
    "Hinge Loss $l(f(x),y) = max(0,1-yf(x))$\n",
    "\n",
    "\\begin{align*}\n",
    "0 &= \\int_Y \\frac{\\partial l(f(x),y)}{\\partial f} d\\rho(y|x) \\\\\n",
    "0 &= \\int_Y \\frac{\\partial \\max(0,1-yf(x))}{\\partial f} d\\rho(y|x) \\\\\n",
    "0 &= \\frac{\\partial \\max(0,1-f(x))}{\\partial f}\\rho(y=1|x) + \\frac{\\partial \\max(0,1+f(x))}{\\partial f}\\rho(y=-1|x)\\\\\n",
    "0 &= \\int_Y -y \\cdot 1_{(yf(x)<1)} d\\rho(y|x) \\\\\n",
    "0 &= -1_{(f(x)<1)}\\rho(y=1|x) + 1_{(f(x)>-1)}\\rho(y=-1|x) \\\\\n",
    "1_{(f_*(x)<1)}\\rho(y=1|x) &= 1_{(f_*(x)>-1)}(1-\\rho(y=1|x))\n",
    "\\end{align*}\n",
    "This can also be expressed as an expectation:\n",
    "$$E\\left[-y \\cdot 1_{(yf(x)<1)} |x \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef2ad3",
   "metadata": {},
   "source": [
    "We choose $f_*(x)$ such that it \"leans\" towards $1$ or $-1$ depending on which of $\\rho(y=1|x)$ or $1-\\rho(y=1|x)$ is larger, to minimise the respective side of the above equation. However we also notice that if $f_*(x) > 1$, then the equation simplifies to indicate $\\rho(y=1|x) = 1$, and similarly if $f_*(x) < -1$ then we observe $\\rho(y=1|x) = 0$. When $-1 < f_*(x) <1$, then $\\rho(y=1|x) = \\rho(y=-1|x) = \\frac{1}{2}$, hence  informing us of constraints on $\\rho$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0839493",
   "metadata": {},
   "source": [
    "### 2.3 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eba8c4",
   "metadata": {},
   "source": [
    "The Bayes decision rule $c_*$ which minimises $R(c)$ over all possible decision rules $c : X \\to \\{-1,1\\}$ is defined as follows:\n",
    "$$c^*(x) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if  } \\rho(y=1|x) \\geq \\rho(y=-1|x)\\\\\n",
    "-1 & \\text{otherwise} \\\\\n",
    "\\end{cases}$$\n",
    "Where the decision rule maps $x=0$ to $1$ in the special case where $\\rho(y=1|x) = \\rho(y=-1|x)$, for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0542db1",
   "metadata": {},
   "source": [
    "### 2.4 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df4d78",
   "metadata": {},
   "source": [
    "Now we aim to understand if the surrogate frameworks in 2.2 are Fisher consistent i.e. we can find a map $d : R \\to \\{-1,1\\}$ such that $R(c_*(x)) = R(d(f_*(x)))$.\n",
    "\n",
    "For the Squared Loss $l(f(x),y) = (f(x)-y)^2$, this is not Fisher consistent as the obtained $f_*(x) = 2\\rho(y=1|x)-1$ captures the mean instead of the mode, and hence may not correctly reflect the underlying class probabilities within the binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d95199",
   "metadata": {},
   "source": [
    "For the Exponential loss $l(f(x),y) = \\exp(-yf(x))$ and Logistic loss $l(f(x),y) = \\log(1+\\exp(-yf(x)))$ functions, we choose $d(f) = sign(f)$ also, since $f_*(x)$ for both surrogate frameworks are such that $R(c_*(x)) = R(d(f_*(x)))$. We define the $sign(x)$ function as follows:\n",
    "$$sign(f) =\n",
    "\\begin{cases}\n",
    "1 & f \\geq 0 \\\\\n",
    "-1 & \\text{otherwise}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "For the Exponential loss, this works as it penalises misclassification exponentially, and hence leads to $d(f(x)) = sign(f(x))$ being effective because the loss function tends to create a strong separation between classes. Similar reasoning applies for the Logistic loss, as the logistic function transforms $f_*(x)$ into a probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63b83d",
   "metadata": {},
   "source": [
    "For the Hinge loss $l(f(x),y) = max(0,1-yf(x))$, we also choose $d(f) = sign(f)$, as the loss function focuses on penalising points on the wrong side of the margin or even too close to the decision boundary. Again, there tends to be a strong separation between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b44a51",
   "metadata": {},
   "source": [
    "### 2.5.1 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864783af",
   "metadata": {},
   "source": [
    "We prove the first intermediate step as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "|R(sign(f))-R(sign(f_*))| &= |E[1_{\\{sign(f(x))\\neq y\\}}]  - E[1_{\\{sign(f_*(x))\\neq y\\}}]| \\\\\n",
    "&= \\int_{X \\times Y} 1_{\\{sign(f(x))\\neq y\\}} - 1_{\\{sign(f_*(x))\\neq y\\}} d\\rho(x,y)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e703b",
   "metadata": {},
   "source": [
    "With $Y = \\{-1, 1\\}$, we know that the integrand will be non-zero when $sign(f(x)) \\neq sign(f_*(x))$ i.e. only on X_f = $\\{x \\in X | sign(f(x)) \\neq sign(f_*(x))\\}$. Hence:\n",
    "\n",
    "\\begin{align*}\n",
    "|R(sign(f))-R(sign(f_*))| &= \\int_{X_f} 1_{\\{sign(f(x))\\neq y\\}} - 1_{\\{sign(f_*(x))\\neq y\\}} d\\rho_X(x)\n",
    "\\end{align*}\n",
    "\n",
    "Over $X_f$, the risk difference is affected by how often $f$ and $f_*$ misclassify, and the magnitude of their differences. $|f_*(x)|$ indicates the 'confidence' of the prediction by $f_*$, since it quantifies how far the prediction is from the decision boundary (which is at 0 for the sign function). Hence we see the integral reduce to the desired result:\n",
    "\n",
    "\\begin{align*}\n",
    "|R(sign(f))-R(sign(f_*))| &= \\int_{X_f} |f_*(x)| d\\rho_X(x)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e0aa9",
   "metadata": {},
   "source": [
    "### 2.5.2 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ccf2b",
   "metadata": {},
   "source": [
    "We continue the intermediate steps as follows. Looking at the first inequality, $|f_*(x)-f(x)|$ represents the distance between $f_*(x)$ and $f(x)$ at each point $x$. Since $|f_*(x)|$ is the distance from $f_*(x)$ to the decision boundary (zero), and when on $X_f$ (where $sign(f(x)) \\neq sign(f_*(x))$), we know that $f(x)$ and $f_*(x)$ are on opposite sides of the decision boundary, and hence $|f_*(x)-f(x)|$ is at least as large as the distance of either point to the decision boundary. Hence $|f_*(x)| \\leq |f_*(x)-f(x)|$, and we continue as follows:\n",
    "\n",
    "$$\\int_{X_f} |f_*(x)| d\\rho_X(x) \\leq \\int_{X_f} |f_*(x)-f(x)| d\\rho_X(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb061de",
   "metadata": {},
   "source": [
    "For the second inequality, we apply Jensen's inequality where for a convex function $g$, we have $E[g(X)] \\geq g(E[X])$. By letting $g(X) = X^2$ which is convex, and taking the square root on both sides, we obtain the result $\\sqrt{E[X^2]} \\geq E[X]$ for a non-negative random variable $X$.\n",
    "\n",
    "Let $X = |f_*(x)-f(x)|$, and we have the following:\n",
    "\n",
    "$$E[|f_*(x)-f(x)|] \\leq \\sqrt{E[|f_*(x)-f(x)|^2]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72200c42",
   "metadata": {},
   "source": [
    "We also note that by simple definition of expectation, that $\\int_{X_f} |f_*(x)-f(x)| d\\rho_X(x) = E[|f_*(x)-f(x)|]$. Combining all results, we have the following:\n",
    "\n",
    "$$\\int_{X_f} |f_*(x)| d\\rho_X(x) \\leq \\int_{X_f} |f_*(x)-f(x)| d\\rho_X(x) \\leq \\sqrt{E[|f_*(x)-f(x)|^2]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974de19",
   "metadata": {},
   "source": [
    "### 2.5.3 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c889b686",
   "metadata": {},
   "source": [
    "Finally, we start with the following:\n",
    "\n",
    "$$\\epsilon(f) - \\epsilon(f_*) = \\int_{X \\times Y} l(f(x),y) -l(f_*(x),y) d\\rho(x,y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7d9f6",
   "metadata": {},
   "source": [
    "Once again, we notice that the losses will cancel each other out when $f(x) = f_*(x)$, hence we are left with the cases on $X_f$. Since we are using the squared loss $l(f(x),y) = (f(x)-y)^2$, we can simplify as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "\\epsilon(f) - \\epsilon(f_*) &= \\int_{X_f} (f(x)-y)^2 -(f_*(x)-y)^2 \\ d\\rho_X(x) \\\\\n",
    "&= \\int_{X_f} f(x)^2 - 2yf(x) + y^2 - f_*(x)^2 + 2yf_*(x) - y^2 \\ d\\rho_X(x) \\\\\n",
    "&= \\int_{X_f} f(x)^2 - f_*(x)^2 - 2y(f(x) - f_*(x))  d\\rho_X(x) \\\\\n",
    "&= \\int_{X_f} f(x)^2 -2f(x)f_*(x) + f_*(x)^2 - 2y(f(x) - f_*(x)) + 2f(x)f_*(x) - 2f_*(x)^2 d\\rho_X(x) \\\\\n",
    "&= \\int_{X_f} (f(x) - f_*(x))^2 - 2y(f(x) - f_*(x)) + 2f_*(x)(f(x) - f_*(x)) d\\rho_X(x) \\\\\n",
    "&= \\int_{X_f} (f(x) - f_*(x))^2 d\\rho_X(x) + 2\\int_{X_f} (f_*(x)-2y)(f(x) - f_*(x)) d\\rho_X(x) \\\\\n",
    "&= E[|f(x) - f_*(x)|^2] + 2 E[(f_*(x)-2y)(f(x) - f_*(x))]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed23f3ec",
   "metadata": {},
   "source": [
    "Since $f_*$ is the minimiser of $\\epsilon(f)$, therefore any variations around $f_*$ i.e. the quantity $(f(x)-f_*(x))$ integrated over the distribution $\\rho$ should all cancel out, resulting in just the first Expectation term. Hence:\n",
    "$$\\epsilon(f) - \\epsilon(f_*) = E[|f(x) - f_*(x)|^2]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea2e34",
   "metadata": {},
   "source": [
    "Combining all results across 2.5, we obtain the final result: (the first inequality to show $\\geq 0$ is trivial as $f_*$ is the minimiser of $\\epsilon(f)$)\n",
    "\n",
    "$$0 \\leq R(sign(f)) - R(sign(f_*)) \\leq \\sqrt{\\epsilon(f) - \\epsilon(f_*)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c63c34",
   "metadata": {},
   "source": [
    "## Part III [40%] {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec407c5a",
   "metadata": {},
   "source": [
    "### Exploration of Kernel Perceptron (Handwritten Digit Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b67ee",
   "metadata": {},
   "source": [
    "In this report, we aim to apply supervised learning techniques to create a classifier for handwritten digits from 0 to 9. We aim to use the perceptron, generalising the perceptron to use kernel functions, and also to employ a One-vs-Rest (OvR) approach to seperate between 2 classes, before then separating $k$ classes.\n",
    "\n",
    "We aim to use a polynomial and gaussian kernel function, with parameters degree $d$ and kernel width $c$ respectively, defined as follows:\n",
    "\\begin{align*}\n",
    "K_d(\\mathbf{p,q}) &= (\\mathbf{p,q})^d \\\\\n",
    "K_c(\\mathbf{p,q}) &= \\exp{(-c||\\mathbf{p-q}||^2)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0cbe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown, Math, Latex\n",
    "import warnings\n",
    "from abc import abstractmethod, ABC\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('zipcombo.dat', delim_whitespace=True, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPerceptron(ABC):\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X_train: np.array, y_train: np.array, d: int):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def evaluate(self, X_train: np.array, X_test: np.array, y_test: np.array, d: int):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbc4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KPOVr(KernelPerceptron):\n",
    "\n",
    "    def __init__(self, num_classifiers: int, max_epochs: int, shuffle: bool, epsilon: float):\n",
    "        self.num_classifiers = num_classifiers\n",
    "        self.max_epochs = max(max_epochs, 10)\n",
    "        self.shuffle = shuffle\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = None\n",
    "        self.kernel_func = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        gram_matrix = self.kernel_func(X_train.values, X_train.values)\n",
    "        self.alpha = np.zeros((self.num_classifiers, X_train.shape[0]))\n",
    "        train_errors = []\n",
    "        for i in range(self.max_epochs):\n",
    "            train_mistakes = 0\n",
    "            if self.shuffle:\n",
    "                indices = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "            else:\n",
    "                indices = np.arange(0, X_train.shape[0], 1)\n",
    "            for example in indices:\n",
    "                y_hat_list = self.alpha @ gram_matrix[:, example]\n",
    "                y_hat_label = np.argmax(y_hat_list)\n",
    "                # Raw label comparison\n",
    "                if y_train.values[example] != y_hat_label:\n",
    "                    self.alpha[y_train.values[example], example] += 1\n",
    "                    self.alpha[y_hat_label, example] -= 1\n",
    "                    train_mistakes += 1\n",
    "            train_error = train_mistakes / X_train.shape[0] * 100\n",
    "            train_errors.append(train_error)\n",
    "            if i > 10:\n",
    "                if np.abs(np.mean(train_errors[i-5:i])-np.mean(train_errors[i-4:i])) < self.epsilon:\n",
    "                    return train_errors[-1]\n",
    "        return train_errors[-1]\n",
    "                \n",
    "    def evaluate(self, X_train, X_test, y_test, confusion_matrix_print: bool, misclassified_points: bool):\n",
    "        gram_matrix = self.kernel_func(X_train.values, X_test.values)\n",
    "        y_hat_label = np.argmax(self.alpha @ gram_matrix, axis=0)\n",
    "        test_error = sum(y_hat_label != y_test.values) / X_test.shape[0] * 100\n",
    "        incorrectly_classified_indices = []  # To store the original indices of misclassified test data\n",
    "        if misclassified_points:\n",
    "            y_test_values = y_test.values.flatten()  # Flatten the y_test DataFrame\n",
    "            incorrectly_classified_indices = y_test.index[y_test_values != y_hat_label].tolist()\n",
    "        if confusion_matrix_print:\n",
    "            confusion_matrix = np.zeros((self.num_classifiers, self.num_classifiers))\n",
    "            for i, j in zip(y_test.values, y_hat_label):\n",
    "                if i != j:\n",
    "                    # Mistake\n",
    "                    confusion_matrix[i, j] += 1\n",
    "            confusion_matrix = np.nan_to_num(confusion_matrix / confusion_matrix.sum(axis=1)[:, np.newaxis])\n",
    "        \n",
    "        if misclassified_points and confusion_matrix_print:\n",
    "            return test_error, confusion_matrix, incorrectly_classified_indices\n",
    "        elif misclassified_points:\n",
    "            return test_error, incorrectly_classified_indices\n",
    "        elif confusion_matrix_print:\n",
    "            return test_error, confusion_matrix\n",
    "        else:\n",
    "            return test_error\n",
    "    \n",
    "    def poly_gram_matrix(self, d):\n",
    "        def kernel_func(x, y):\n",
    "            return (x @ y.T) ** d\n",
    "\n",
    "        self.kernel_func = kernel_func\n",
    "\n",
    "    def gaussian_gram_matrix(self, c):\n",
    "        def kernel_func(x, y):\n",
    "            dist_matrix = cdist(x, y)\n",
    "            return np.exp(-c * dist_matrix**2)\n",
    "\n",
    "        self.kernel_func = kernel_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, shuffle_df=True, split_ratio=0.8):\n",
    "    split_idx = int(len(df) * split_ratio)\n",
    "    if shuffle_df:\n",
    "        df_shf = df.sample(frac=1.0)\n",
    "    train_idx, test_idx = df_shf[:split_idx], df_shf[split_idx:]\n",
    "\n",
    "    # Correct column indexing to start from 0 for Y (outputs)\n",
    "    X_train, y_train = train_idx.iloc[:, 1:], train_idx.iloc[:, 0].astype(int)\n",
    "    X_test, y_test = test_idx.iloc[:, 1:], test_idx.iloc[:, 0].astype(int)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b9139",
   "metadata": {},
   "source": [
    "### 3.1: Basic Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cb990b",
   "metadata": {},
   "source": [
    "First, we used the polynomial kernel function without cross validation to compute training and testing errors for degrees $d$ from $\\{1, 2, \\cdots, 7\\}$, displaying the mean $\\mu$ and standard deviation over 20 runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c82ed52",
   "metadata": {},
   "source": [
    "| **d (degree)** | **Train Error** $(\\mu \\pm \\sigma)$ in % | **Test Error** $(\\mu \\pm \\sigma)$ in % |\n",
    "|----------------|-----------------|----------------|\n",
    "| 1              | $5.7045 \\pm 0.2753$ | $8.6237 \\pm 0.9705$ |\n",
    "| 2              | $0.2978 \\pm 0.0825$ | $3.5618 \\pm 0.4188$  |\n",
    "| 3              | $0.0867 \\pm 0.0447$ | $3.2903 \\pm 0.3605$  |\n",
    "| 4              | $0.0592 \\pm 0.0453$ | $3.1667 \\pm 0.3318$  |\n",
    "| 5              | $0.0524 \\pm 0.0427$ | $3.1505 \\pm 0.5811$  |\n",
    "| 6              | $0.0612 \\pm 0.0409$ | $2.9462 \\pm 0.4286$  |\n",
    "| 7              | $0.0504 \\pm 0.0505$ | $3.0780 \\pm 0.3939$  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e061d",
   "metadata": {},
   "source": [
    "Here, we observe that the degrees $d$ which seem to obtain the lowest test errors are in the region $4 \\leq d \\leq 7$. $d=1$ stands out with a significantly large test error of 8%+. This suggests that a polynomial degree of 1 is significantly unable to capture the patterns and intricacies of digits, which appears sensical as the images are in 2D. For $d=2$ onwards, the errors are similar yet still decreasing for larger $d$, for both training and testing. With an error rate of ~3%, this suggests a good start to a strong model, and motivates cross validation to identify the optimal degree $d$. We must also be wary of overfitting for higher degrees $d$, hence we may lean towards $d = 4$ or $d = 5$ as there is lesser improvement to the test error for $d > 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d62ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3_1(model, degrees, df, confusion_matrix_print: bool, misclassified_points: bool, num_runs=20):\n",
    "    results = {d: {'train_errors': [], 'test_errors': []} for d in degrees}\n",
    "    for d in degrees:\n",
    "        model.poly_gram_matrix(d)\n",
    "        for run in range(num_runs):\n",
    "            X_train, y_train, X_test, y_test = train_test_split(df)\n",
    "            # Train perceptrons for the current degree (d) and calculate error rates\n",
    "            train_error = model.fit(X_train, y_train)\n",
    "            test_error = model.evaluate(X_train, X_test, y_test, confusion_matrix, misclassified_points)\n",
    "            # print('train_error =', train_error, '; test_error =', test_error)\n",
    "\n",
    "            results[d]['train_errors'].append(train_error)\n",
    "            results[d]['test_errors'].append(test_error)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d4820",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KPOVr(10, 15, True, 0.001)\n",
    "degrees = range(1,8)\n",
    "results3_1 = question3_1(model, degrees, df, False, False, num_runs=20)\n",
    "\n",
    "for d in degrees:\n",
    "    train_mean = np.mean(results3_1[d]['train_errors'])\n",
    "    train_std = np.std(results3_1[d]['train_errors'])\n",
    "    test_mean = np.mean(results3_1[d]['test_errors'])\n",
    "    test_std = np.std(results3_1[d]['test_errors'])\n",
    "\n",
    "    print(f\"d = {d}: Train Error = {train_mean:.4f} ± {train_std:.4f}, Test Error = {test_mean:.4f} ± {test_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df7af1",
   "metadata": {},
   "source": [
    "### 3.2 & 3.3: Cross-validation & Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad7174",
   "metadata": {},
   "source": [
    "We now perform 5-fold cross-validation to select the best degree parameter $d^*$. We then retrain the model using $d^*$ to identify the test errors on the full data set again, over 20 runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5b3a4",
   "metadata": {},
   "source": [
    "| Mean **$d^*$** with std | **Test Error** $(\\mu \\pm \\sigma)$ in % |\n",
    "|-----------------|----------------|\n",
    "| $4.7 \\pm 1.1000$ | $3.1452 \\pm 0.3246$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6bdef",
   "metadata": {},
   "source": [
    "Here we identify the mean $d^*$ similarly to our ideas from 3.1. However the standard deviation is relatively high, also confirming that degrees in the range $4 \\leq d \\leq 7$ are producing similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aebe67",
   "metadata": {},
   "source": [
    "We now provide a confusion matrix, providing the errors for digit $a$ being mistaken for digit $b$, averaged over 20 runs in which the optimal $d^*$ was found via cross-validation and used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495a495",
   "metadata": {},
   "source": [
    "|       | 0               | 1               | 2               | 3               | 4               | 5               | 6               | 7               | 8               | 9               |\n",
    "|-------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|-----------------|\n",
    "| 0     | 0.000 ± 0.000   | 0.020 ± 0.060   | 0.154 ± 0.170   | 0.174 ± 0.152   | 0.064 ± 0.109   | 0.130 ± 0.164   | 0.222 ± 0.239   | 0.037 ± 0.074   | 0.100 ± 0.300   | 0.100 ± 0.170   |\n",
    "| 1     | 0.000 ± 0.000   | 0.000 ± 0.000   | 0.100 ± 0.200   | 0.000 ± 0.000   | 0.250 ± 0.261   | 0.000 ± 0.000   | 0.250 ± 0.344   | 0.100 ± 0.300   | 0.100 ± 0.200   | 0.000 ± 0.000   |\n",
    "| 2     | 0.083 ± 0.117   | 0.088 ± 0.116   | 0.000 ± 0.000   | 0.093 ± 0.120   | 0.237 ± 0.174   | 0.010 ± 0.030   | 0.074 ± 0.180   | 0.207 ± 0.129   | 0.180 ± 0.170   | 0.029 ± 0.057   |\n",
    "| 3     | 0.031 ± 0.065   | 0.018 ± 0.037   | 0.121 ± 0.119   | 0.000 ± 0.000   | 0.011 ± 0.033   | 0.502 ± 0.169   | 0.000 ± 0.000   | 0.080 ± 0.092   | 0.219 ± 0.178   | 0.018 ± 0.055   |\n",
    "| 4     | 0.021 ± 0.046   | 0.159 ± 0.168   | 0.235 ± 0.119   | 0.055 ± 0.081   | 0.000 ± 0.000   | 0.090 ± 0.126   | 0.153 ± 0.134   | 0.053 ± 0.083   | 0.053 ± 0.057   | 0.180 ± 0.122   |\n",
    "| 5     | 0.221 ± 0.180   | 0.000 ± 0.000   | 0.036 ± 0.063   | 0.230 ± 0.132   | 0.054 ± 0.107   | 0.000 ± 0.000   | 0.270 ± 0.192   | 0.019 ± 0.040   | 0.100 ± 0.095   | 0.070 ± 0.120   |\n",
    "| 6     | 0.380 ± 0.293   | 0.087 ± 0.129   | 0.140 ± 0.166   | 0.000 ± 0.000   | 0.257 ± 0.207   | 0.127 ± 0.144   | 0.000 ± 0.000   | 0.000 ± 0.027   | 0.009 ± 0.000   | 0.000 ± 0.000   |\n",
    "| 7     | 0.000 ± 0.000   | 0.053 ± 0.111   | 0.189 ± 0.206   | 0.069 ± 0.117   | 0.240 ± 0.201   | 0.000 ± 0.000   | 0.000 ± 0.000   | 0.000 ± 0.000   | 0.139 ± 0.198   | 0.308 ± 0.247   |\n",
    "| 8     | 0.116 ± 0.148   | 0.066 ± 0.086   | 0.171 ± 0.164   | 0.267 ± 0.125   | 0.144 ± 0.158   | 0.078 ± 0.073   | 0.037 ± 0.057   | 0.051 ± 0.084   | 0.000 ± 0.000   | 0.070 ± 0.075   |\n",
    "| 9     | 0.020 ± 0.060   | 0.000 ± 0.000   | 0.110 ± 0.097   | 0.070 ± 0.155   | 0.405 ± 0.237   | 0.037 ± 0.075   | 0.000 ± 0.000   | 0.359 ± 0.276   | 0.000 ± 0.000   | 0.000 ± 0.000   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3257d7e7",
   "metadata": {},
   "source": [
    "We observe that there are indeed zeros across the diagonal, as correctly identified digits will have zero error by definition. There doesn't appear to be any significant trends or particular differences between digits, however upon adding the columns of each row which represent how many times that digit was misclassified, we identify that the digit $4$ has a particular high error rate and the digit $1$ has a particular low error rate. Of course, we cannot strictly add each number as these are rates, but we still gain a sense of which digits are more difficult to analyse than others. With $4$ being the most erroneous, due to its complexity and from even having multiple ways to write it, and $1$ being the les erroneous due to its simplicity, the results seem to match intuition here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a11a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3_2(model, degrees, df, confusion_matrix_print: bool, misclassified_points: bool, num_runs=20, num_folds=5):\n",
    "    best_ds = []  # To store the best d for each run\n",
    "    test_errors = []  # To store the test errors for each run\n",
    "    confusion_matrices = []  # To store the confusion matrices for each run\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        print(f\"run = {run+1}\")\n",
    "        X_train, y_train, X_test, y_test = train_test_split(df)\n",
    "        fold_size = len(X_train) // num_folds\n",
    "        best_d = None\n",
    "        best_validation_error = float('inf')\n",
    "\n",
    "        for d in degrees:\n",
    "            print(f\"d = {d}\")\n",
    "            model.poly_gram_matrix(d)\n",
    "            validation_errors = []\n",
    "\n",
    "            for fold in range(num_folds):\n",
    "                start = fold * fold_size\n",
    "                end = (fold + 1) * fold_size\n",
    "                X_fold = X_train.iloc[start:end]\n",
    "                y_fold = y_train.iloc[start:end]\n",
    "                mask = ~X_train.index.isin(range(start, end))\n",
    "                X_remainder = X_train[mask]\n",
    "                y_remainder = y_train[mask]\n",
    "\n",
    "                model.fit(X_remainder, y_remainder)\n",
    "                validation_error = model.evaluate(X_remainder, X_fold, y_fold, False, False)\n",
    "                validation_errors.append(validation_error)\n",
    "\n",
    "            mean_validation_error = np.mean(validation_errors)\n",
    "            if mean_validation_error < best_validation_error:\n",
    "                best_validation_error = mean_validation_error\n",
    "                best_d = d\n",
    "\n",
    "        # Retrain with the best d on the full 80% training set\n",
    "        model.poly_gram_matrix(best_d)\n",
    "        model.fit(X_train, y_train)\n",
    "        test_error, confusion_matrix = model.evaluate(X_train, X_test, y_test, confusion_matrix_print, misclassified_points)\n",
    "        print(f\"Best d: {best_d}, Test Error: {test_error:.4f}\\n\")\n",
    "        best_ds.append(best_d)\n",
    "        test_errors.append(test_error)\n",
    "        confusion_matrices.append(confusion_matrix)\n",
    "\n",
    "    return best_ds, test_errors, confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f58f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "model = KPOVr(10, 15, True, 0.001)\n",
    "degrees = range(1, 8)\n",
    "best_ds, test_errors, confusion_matrices = question3_2(model, degrees, df, True, False, num_runs=10, num_folds=5)\n",
    "confusion_matrices = np.array(confusion_matrices)\n",
    "\n",
    "mean_best_d = np.mean(best_ds)\n",
    "std_best_d = np.std(best_ds)\n",
    "mean_test_error = np.mean(test_errors)\n",
    "std_test_error = np.std(test_errors)\n",
    "mean_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "std_confusion_matrix = np.std(confusion_matrices, axis=0)\n",
    "\n",
    "print(f\"Mean Best d: {mean_best_d:.4f} ± {std_best_d:.4f}\")\n",
    "print(f\"Mean Test Error: {mean_test_error:.4f} ± {std_test_error:.4f}\")\n",
    "\n",
    "print(\"Mean Confusion Matrix:\")\n",
    "display(pd.DataFrame(mean_confusion_matrix))\n",
    "print(\"\\nStandard Deviation Confusion Matrix:\")\n",
    "display(pd.DataFrame(std_confusion_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933d9779",
   "metadata": {},
   "source": [
    "### 3.4: Hardest images to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f168acb2",
   "metadata": {},
   "source": [
    "We aim to identify the top 5 hardest images to predict correctly from the entire dataset. We achieve this by training the model over 100 runs, and counting the frequency of each image being predicted incorrectly in the testing phase, and divide by the number of times that each image appeared in the test set at all. We increased the number of runs from 20 to 100, as random shuffles of the dataset mean that some images may be tested more often than others, hence increasing the number of runs allows a fairer test to occur. We trained the model with $d=5$, assuming it as the best degree from the prior cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dcf4a8",
   "metadata": {},
   "source": [
    "We first sort by the misclassification ratios which are the highest, and then by the number of times it was misclassified, if the ratios were the same. On testing, it showed ~50 images had a 100% misclassification rate, hence the need to narrow down further. We could reduce this pool by increasing the number of runs much above 100, however we still understand that the images of these digits are not particularly 'clear' or 'well-drawn' and I find it unsurprising that these are hard to predict. With digits completely stretched and warped, it would require a model which could identify much more finer details and patterns. This is not achievable by a perceptron algorithm, perhaps a convolutional neural network would be more success.\n",
    "\n",
    "Zooming in further, the top 5 hardest to predict digits included an vertically stretched 6 and 4, which the algorithm may understandly perceive as a 1. The model would need to distinguish between regions with only 3 pixels, to say, understand if there is a 'hole' in the 6 or 4 or not, which is possible for the human eye but without a cNN or potentially higher degree $d$ is unfeasible. In addition, a correct label of zero was attributed to what even a human would perceive as a horizontal smudged line. There is another example (which did not appear in my top 5) which is an almost indistinguishable example to this, but has 7 as the correct label. This reassures the model's strength as it is almost better to predict these (albeit minority) images as incorrect, to not overfit and learn the wrong 'habits'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3_4(model, d, df, confusion_matrix_print: bool, misclassified_points: bool, num_runs=20):\n",
    "    num_points = len(df)\n",
    "    misclassified_counts = np.zeros(num_points)\n",
    "    appearance_counts = np.zeros(num_points)\n",
    "    model.poly_gram_matrix(d)\n",
    "    for run in range(num_runs):\n",
    "        X_train, y_train, X_test, y_test = train_test_split(df)\n",
    "        model.fit(X_train, y_train)\n",
    "        # Calculate the error rate for the testing phase and count misclassified points\n",
    "        _, incorrectly_classified_indices = model.evaluate(X_train, X_test, y_test, False, True)\n",
    "        misclassified_counts[incorrectly_classified_indices] += 1\n",
    "        appearance_counts[X_test.index] += 1\n",
    "    # Avoid division by zero\n",
    "    appearance_counts[appearance_counts == 0] = 1\n",
    "    return misclassified_counts, appearance_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KPOVr(10, 15, True, 0.001)\n",
    "degree = 5\n",
    "misclassified_counts, appearance_counts = question3_4(model, degree, df, False, True, num_runs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461fbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_ratios = misclassified_counts / appearance_counts\n",
    "\n",
    "# Custom sorting key\n",
    "sorting_key = np.lexsort((-misclassification_ratios, -misclassified_counts))\n",
    "\n",
    "top_N = 5\n",
    "top_5_indices = sorting_key[:top_N]\n",
    "\n",
    "# Print the results\n",
    "for index in top_5_indices:\n",
    "    print(f\"Index {index}: Misclassification Ratio {misclassification_ratios[index]}, Misclassified Count {misclassified_counts[index]}\")\n",
    "\n",
    "top5_hardest_images = df.iloc[:, 1:].iloc[top_5_indices]\n",
    "top5_hardest_labels = df.iloc[:, 0].iloc[top_5_indices]\n",
    "\n",
    "# Visualize the top 5 hardest-to-predict images\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(top_N):\n",
    "    plt.subplot(1, top_N, i + 1)\n",
    "    plt.imshow(top5_hardest_images.iloc[i].values.reshape(16, 16), cmap='gray')\n",
    "    plt.title(f\"Label: {top5_hardest_labels.iloc[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a657c8",
   "metadata": {},
   "source": [
    "### 3.5: Gaussian Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ed224",
   "metadata": {},
   "source": [
    "We now consider a Gaussian kernel function instead of a polynomial kernel function. We now deal with a parameter $c$ as the width of the kernel. After initial experiments of trying $c = \\{0.001, 0.01, 0.1, 1, 10, 100\\}$ to identify the optimal magnitude of $c$ to minimise the test error, we identify $c = 0.01$ as a suitable magnitude. Hence we select the range of $c$ values $S$, to be $[0.005, 0.01, 0.02, 0.03, 0.04]$. We first average training and test errors over 20 runs for each value of $c \\in S$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6709b9",
   "metadata": {},
   "source": [
    "| **c**       | **Train Error** $(\\mu \\pm \\sigma)$ in % | **Test Error** $(\\mu \\pm \\sigma)$ in % |\n",
    "|-------------|----------------------------------------|--------------------------------------|\n",
    "| 0.005       | $0.1627 \\pm 0.0835$                   | $3.3602 \\pm 0.4170$                 |\n",
    "| 0.01        | $0.0565 \\pm 0.0426$                   | $3.0591 \\pm 0.4514$                 |\n",
    "| 0.02        | $0.0457 \\pm 0.0316$                   | $3.0108 \\pm 0.3713$                 |\n",
    "| 0.03        | $0.0175 \\pm 0.0181$                   | $3.3548 \\pm 0.5016$                 |\n",
    "| 0.04        | $0.0188 \\pm 0.0210$                   | $3.5645 \\pm 0.3332$                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9102ea8c",
   "metadata": {},
   "source": [
    "This table highlights the errors for each value of $c$ from our chosen $S$, which was centered around an initial run to identify magnitude. We obtain very strong and similar values for the test error, for an optimal $c$ of $c^* = 0.02$. However once again, the lack of robustness/confidence in this value due to the very similar test errors for surrounding values of $c$, motivate the need for 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c968e",
   "metadata": {},
   "source": [
    "| Mean **$c^*$** with std | **Test Error** $(\\mu \\pm \\sigma)$ in % |\n",
    "|-----------------|----------------|\n",
    "| $0.016 \\pm 0.0450$ | $3.0257 \\pm 0.5012$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3_5(model, c_widths, df, confusion_matrix_print: bool, misclassified_points: bool, num_runs=20):\n",
    "    results = {c: {'train_errors': [], 'test_errors': []} for c in c_widths}\n",
    "    for c in c_widths:\n",
    "        print('c =', c)\n",
    "        model.gaussian_gram_matrix(c)\n",
    "        for run in range(num_runs):\n",
    "            X_train, y_train, X_test, y_test = train_test_split(df)\n",
    "            # Train perceptrons for the current width (c) and calculate error rates\n",
    "            train_error = model.fit(X_train, y_train)\n",
    "            test_error = model.evaluate(X_train, X_test, y_test, confusion_matrix_print, misclassified_points)\n",
    "\n",
    "            results[c]['train_errors'].append(train_error)\n",
    "            results[c]['test_errors'].append(test_error)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f9cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KPOVr(10, 15, True, 0.001)\n",
    "c_widths = [0.005, 0.01, 0.02, 0.03, 0.04]\n",
    "results3_5 = question3_5(model, c_widths, df, False, False, num_runs=20)\n",
    "\n",
    "for c in c_widths:\n",
    "    train_mean = np.mean(results3_5[c]['train_errors'])\n",
    "    train_std = np.std(results3_5[c]['train_errors'])\n",
    "    test_mean = np.mean(results3_5[c]['test_errors'])\n",
    "    test_std = np.std(results3_5[c]['test_errors'])\n",
    "\n",
    "    print(f\"c = {c}: Train Error = {train_mean:.4f} ± {train_std:.4f}, Test Error = {test_mean:.4f} ± {test_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f276c26",
   "metadata": {},
   "source": [
    "We then perform 5-fold cross-validation to identify the optimal $c^*$ over 20 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc28ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3_5_cv(model, c_widths, df, confusion_matrix_print: bool, misclassified_points: bool, num_runs=20, num_folds=5):\n",
    "    best_cs = []  # To store the best c for each run\n",
    "    test_errors = []  # To store the test errors for each run\n",
    "    confusion_matrices = []  # To store the confusion matrices for each run\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        print(f\"Run {run + 1}\")\n",
    "        X_train, y_train, X_test, y_test = train_test_split(df)\n",
    "        fold_size = len(X_train) // num_folds\n",
    "        best_c = None\n",
    "        best_validation_error = float('inf')\n",
    "\n",
    "        for c in c_widths:\n",
    "            model.gaussian_gram_matrix(c)\n",
    "            validation_errors = []\n",
    "\n",
    "            for fold in range(num_folds):\n",
    "                start = fold * fold_size\n",
    "                end = (fold + 1) * fold_size\n",
    "                X_fold = X_train.iloc[start:end]\n",
    "                y_fold = y_train.iloc[start:end]\n",
    "                mask = ~X_train.index.isin(range(start, end))\n",
    "                X_remainder = X_train[mask]\n",
    "                y_remainder = y_train[mask]\n",
    "\n",
    "                model.fit(X_remainder, y_remainder)\n",
    "                validation_error = model.evaluate(X_remainder, X_fold, y_fold, False, False)\n",
    "                validation_errors.append(validation_error)\n",
    "\n",
    "            mean_validation_error = np.mean(validation_errors)\n",
    "            if mean_validation_error < best_validation_error:\n",
    "                best_validation_error = mean_validation_error\n",
    "                best_c = c\n",
    "\n",
    "        # Retrain with the best c on the full 80% training set\n",
    "        model.gaussian_gram_matrix(best_c)\n",
    "        model.fit(X_train, y_train)\n",
    "        test_error = model.evaluate(X_train, X_test, y_test, confusion_matrix_print, misclassified_points)\n",
    "        print(f\"Best c: {best_c}, Test Error: {test_error:.4f}\\n\")\n",
    "\n",
    "        best_cs.append(best_c)\n",
    "        test_errors.append(test_error)\n",
    "\n",
    "    return best_cs, test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b806b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "model = KPOVr(10, 15, True, 0.001)\n",
    "c_widths = [0.005, 0.01, 0.02, 0.03, 0.04]\n",
    "best_cs, test_errors = question3_5_cv(model, c_widths, df, False, False, num_runs=1, num_folds=5)\n",
    "\n",
    "mean_best_c = np.mean(best_cs)\n",
    "std_best_c = np.std(best_cs)\n",
    "mean_test_error = np.mean(test_errors)\n",
    "std_test_error = np.std(test_errors)\n",
    "\n",
    "print(f\"Mean Best c: {mean_best_c:.4f} ± {std_best_c:.4f}\")\n",
    "print(f\"Mean Test Error: {mean_test_error:.4f} ± {std_test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79060049",
   "metadata": {},
   "source": [
    "### 3.6: Alternate Method: One-vs-One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b2360",
   "metadata": {},
   "source": [
    "Now we employ a One-vs-One approach, as opposed to One-vs-Rest, to generalise the kernel perceptron to $k$-classes. This is computationally more expensive, however allows for direct comparisons between classes and may prevent the classifier from predicting a image to be multiple classes with high probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63c05e",
   "metadata": {},
   "source": [
    "| **d**       | **Train Error** $(\\mu \\pm \\sigma)$ in % | **Test Error** $(\\mu \\pm \\sigma)$ in % |\n",
    "|-------|-----------------|----------------|\n",
    "| 1     | $1.6364 \\pm 0.0493$ | $0.3538 \\pm 0.0823$ |\n",
    "| 2     | $0.0542 \\pm 0.0132$ | $0.3201 \\pm 0.0733$ |\n",
    "| 3     | $0.0247 \\pm 0.0097$ | $0.2771 \\pm 0.0659$ |\n",
    "| 4     | $0.0167 \\pm 0.0106$ | $0.2596 \\pm 0.0616$ |\n",
    "| 5     | $0.0124 \\pm 0.0108$ | $0.2512 \\pm 0.0723$ |\n",
    "| 6     | $0.0085 \\pm 0.0072$ | $0.2612 \\pm 0.0545$ |\n",
    "| 7     | $0.0122 \\pm 0.0083$ | $0.2671 \\pm 0.0560$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d786a6",
   "metadata": {},
   "source": [
    "Here we observe slightly lower test errors compared to One-vs-Rest, with lower standard deviations as well. This indicates a strong model, however once again there is ambiguity over the optimal $d^*$, so we perform 5-fold cross validation with the following results:\n",
    "\n",
    "| Mean **$d^*$** with std | **Test Error** $(\\mu \\pm \\sigma)$ in % |\n",
    "|-----------------|----------------|\n",
    "| $4.3 \\pm 0.714$ | $0.2623 \\pm 0.0393$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2728bc46",
   "metadata": {},
   "source": [
    "After 5-fold cross validation, we obtain an optimal $d^*$ which is also lower than that of One-vs-Rest, perhaps since there is less complexity within a decision boundary between 2 digits, as opposed to differentiating between 1 and 9 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KPOVo(KernelPerceptron):\n",
    "    def __init__(self, num_classes: int, max_epochs: int, shuffle: bool, epsilon: float):\n",
    "        self.num_classes = num_classes\n",
    "        self.max_epochs = max(max_epochs, 10)\n",
    "        self.shuffle = shuffle\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = None\n",
    "        self.kernel_func = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        gram_matrix = self.kernel_func(X_train.values, X_train.values)\n",
    "        self.alpha = np.zeros((self.num_classes, self.num_classes, X_train.shape[0]))\n",
    "        train_errors = []\n",
    "\n",
    "        for i in range(self.max_epochs):\n",
    "            train_mistakes = 0\n",
    "\n",
    "            if self.shuffle:\n",
    "                indices = np.random.choice(X_train.shape[0], X_train.shape[0], replace=False)\n",
    "            else:\n",
    "                indices = np.arange(0, X_train.shape[0], 1)\n",
    "\n",
    "            for example in indices:\n",
    "                for class1 in range(self.num_classes):\n",
    "                    for class2 in range(class1 + 1, self.num_classes):\n",
    "                        y_class1 = self.alpha[class1, class2] @ gram_matrix[:, example]\n",
    "                        y_class2 = self.alpha[class2, class1] @ gram_matrix[:, example]\n",
    "\n",
    "                        if y_train.values[example] == class1:\n",
    "                            if y_class1 <= y_class2:\n",
    "                                self.alpha[class1, class2, example] += 1\n",
    "                                train_mistakes += 1\n",
    "                        else:\n",
    "                            if y_class2 <= y_class1:\n",
    "                                self.alpha[class2, class1, example] += 1\n",
    "                                train_mistakes += 1\n",
    "\n",
    "            train_error = train_mistakes / (X_train.shape[0] * self.num_classes * (self.num_classes - 1) / 2) * 100\n",
    "            train_errors.append(train_error)\n",
    "\n",
    "            if i > 10:\n",
    "                if np.abs(np.mean(train_errors[i - 5:i]) - np.mean(train_errors[i - 4:i])) < self.epsilon:\n",
    "                    return train_errors[-1]\n",
    "\n",
    "        return train_errors[-1]\n",
    "\n",
    "    def evaluate(self, X_train, X_test, y_test):\n",
    "        gram_matrix = self.kernel_func(X_train.values, X_test.values)\n",
    "        num_test_samples = X_test.shape[0]\n",
    "        num_combinations = self.num_classes * (self.num_classes - 1) // 2\n",
    "\n",
    "        class_pairs = [(class1, class2) for class1 in range(self.num_classes) for class2 in range(class1 + 1, self.num_classes)]\n",
    "        y_hat_labels = np.zeros((num_combinations, num_test_samples))\n",
    "\n",
    "        for idx, (class1, class2) in enumerate(class_pairs):\n",
    "            y_class1 = self.alpha[class1, class2] @ gram_matrix\n",
    "            y_class2 = self.alpha[class2, class1] @ gram_matrix\n",
    "            y_hat_labels[idx] = (y_class1 <= y_class2)\n",
    "\n",
    "        y_test_matrix = np.zeros((num_combinations, num_test_samples))\n",
    "        for idx, (class1, class2) in enumerate(class_pairs):\n",
    "            y_test_matrix[idx] = (y_test.values == class1) | (y_test.values == class2)\n",
    "\n",
    "        test_error = np.mean(np.sum(y_hat_labels != y_test_matrix, axis=0) > 0) / num_test_samples * 100\n",
    "\n",
    "        return test_error\n",
    "    \n",
    "    def poly_gram_matrix(self, d):\n",
    "        def kernel_func(x, y):\n",
    "            return (x @ y.T) ** d\n",
    "        self.kernel_func = kernel_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ea8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3_6(model, degrees, df, num_runs=20):\n",
    "    results = {d: {'train_errors': [], 'test_errors': []} for d in degrees}\n",
    "    for d in degrees:\n",
    "        print(f\"d = {d}\")\n",
    "        model.poly_gram_matrix(d)\n",
    "        for run in range(num_runs):\n",
    "            print(f\"run = {run+1}\")\n",
    "            X_train, y_train, X_test, y_test = train_test_split(df)\n",
    "            # Train perceptrons for the current degree (d) and calculate error rates\n",
    "            train_error = model.fit(X_train, y_train)\n",
    "            test_error = model.evaluate(X_train, X_test, y_test)\n",
    "            # print('train_error =', train_error, '; test_error =', test_error)\n",
    "            results[d]['train_errors'].append(train_error)\n",
    "            results[d]['test_errors'].append(test_error)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacb0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KPOVo(10, 15, True, 0.001)\n",
    "degrees = range(1,8)\n",
    "results3_6 = question3_6(model, degrees, df, num_runs=20)\n",
    "\n",
    "for d in degrees:\n",
    "    train_mean = np.mean(results3_6[d]['train_errors'])\n",
    "    train_std = np.std(results3_6[d]['train_errors'])\n",
    "    test_mean = np.mean(results3_6[d]['test_errors'])\n",
    "    test_std = np.std(results3_6[d]['test_errors'])\n",
    "\n",
    "    print(f\"d = {d}: Train Error = {train_mean:.4f} ± {train_std:.4f}, Test Error = {test_mean:.4f} ± {test_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question3_6_cv(model, degrees, df, num_runs=20, num_folds=5):\n",
    "    best_ds = []  # To store the best d for each run\n",
    "    test_errors = []  # To store the test errors for each run\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        X_train, y_train, X_test, y_test = train_test_split(df)\n",
    "        fold_size = len(X_train) // num_folds\n",
    "        best_d = None\n",
    "        best_validation_error = float('inf')\n",
    "\n",
    "        for d in degrees:\n",
    "            model.poly_gram_matrix(d)\n",
    "            validation_errors = []\n",
    "\n",
    "            for fold in range(num_folds):\n",
    "                start = fold * fold_size\n",
    "                end = (fold + 1) * fold_size\n",
    "                X_fold = X_train.iloc[start:end]\n",
    "                y_fold = y_train.iloc[start:end]\n",
    "                mask = ~X_train.index.isin(range(start, end))\n",
    "                X_remainder = X_train[mask]\n",
    "                y_remainder = y_train[mask]\n",
    "\n",
    "                model.fit(X_remainder, y_remainder)\n",
    "                validation_error = model.evaluate(X_remainder, X_fold, y_fold)\n",
    "                validation_errors.append(validation_error)\n",
    "\n",
    "            mean_validation_error = np.mean(validation_errors)\n",
    "            if mean_validation_error < best_validation_error:\n",
    "                best_validation_error = mean_validation_error\n",
    "                best_d = d\n",
    "\n",
    "        # Retrain with the best d on the full 80% training set\n",
    "        model.poly_gram_matrix(best_d)\n",
    "        model.fit(X_train, y_train)\n",
    "        test_error = model.evaluate(X_train, X_test, y_test)\n",
    "        print(f\"Best d: {best_d}, Test Error: {test_error:.4f}\\n\")\n",
    "        best_ds.append(best_d)\n",
    "        test_errors.append(test_error)\n",
    "\n",
    "    return best_ds, test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation\n",
    "model = KPOVo(10, 15, True, 0.001)\n",
    "degrees = range(1, 8)\n",
    "best_ds, test_errors = question3_6_cv(model, degrees, df, num_runs=20, num_folds=5)\n",
    "\n",
    "mean_best_d = np.mean(best_ds)\n",
    "std_best_d = np.std(best_ds)\n",
    "mean_test_error = np.mean(test_errors)\n",
    "std_test_error = np.std(test_errors)\n",
    "\n",
    "print(f\"Mean Best d: {mean_best_d:.4f} ± {std_best_d:.4f}\")\n",
    "print(f\"Mean Test Error: {mean_test_error:.4f} ± {std_test_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb9b56",
   "metadata": {},
   "source": [
    "### Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863c8250",
   "metadata": {},
   "source": [
    "#### 3.A\n",
    "\n",
    "Regarding parameters which were not cross-validated over, we identify a few which were not explored by choice. We could have identified the optimal maximum number of epochs \"max_epochs\", which may differ per kernel or dataset. However since the obtained test errors were sufficiently low, there was little potential gain from increasing the number of epochs and risk overfitting. In addition, epsilon as the convergence threshold could have been optimised from being fixed at 0.001. However, in a similar nature, the test errors were sufficiently low and there was little to gain from extending the training time by potentially decreasing epsilon. The number of classifiers remains trivially unchanged as contextually we are aware of exactly 10 classes, by the total number of unique labels in the data set (and human knowledge of our 10 digits).\n",
    "\n",
    "#### 3.B\n",
    "\n",
    "Initially we opted for the One-vs-Rest (OvR) approach where we train $k$ separate binary classifiers, one for each class. Each classifier treats one class as positive and the rest as negative. This has advantages since it is computationally efficient, as we only create $k$ classifiers for the $k$ classes. One potential issue involves non-transitive comparisons, where a particular image might be classified as multiple classes with high confidence.\n",
    "\n",
    "The other approach involves One-vs-One (OvO), where a binary classifier is trained for every pair of classes. With $k$ classes, we will have $\\frac{1}{2}k(k-1)$ classifiers, which is of course more computationally expensive compared to OvA. However, we do remove the issue of non-transitive comparisons since we distinguish between only 2 classes, rather than 1 class distinguished against $k-1$ classes.\n",
    "\n",
    "In terms of our results, we find the OvO had a slightly better performance than OvA in terms of both mean and std testing errors, and also showed a slightly lower $d^*$ for the polynomial kernel. At first glance, this could be due to an imbalanced dataset, as OvO tends to be less sensitive to this issue, however across the entire dataset, it is mostly balanced with the mode digit appearing ~1500 times, and the least frequent appearing ~700 times. There is some imbalance, but still heuristically one can argue that there is sufficient examples of all digits to not mean OvO has a huge improvement. Given the significantly longer computation time for OvO compared to OvR, it becomes more difficult to conclude on a better algorithm.\n",
    "\n",
    "#### 3.C\n",
    "\n",
    "Initially we trained with the polynomial kernel, with degree parameter $d$ representing the polynomial degree. Higher degree polynomials can capture more complex relationships in the data, however we want to balance this against too high of a degree which could lead to overfitting. The Gaussian kernel with width parameter $c$ controlling the kernel's width. Smaller $c$ values lead to a wider kernel, which may cause underfitting, however if $c$ is too small then we may overfit. The Gaussian kernel is more computationally expensive compared to the polynomial kernel, as it involving computing Euclidean distances. Gaussian kernels more robust and less susceptible to noise.\n",
    "\n",
    "In terms of our results, both kernels appeared to produce similar test errors at their optimal parameters (~3% test error rate), however the gaussian kernel took significantly longer to compute.\n",
    "\n",
    "#### 3.D\n",
    "\n",
    "In the implementation for OvR from 3.1, we discuss the sum $w(\\cdot) = \\sum_{i=0}^m \\alpha_i K(x_i, \\cdot)$ and how new terms are added to the sum during training. The sum of $w$ was represented by a matrix multiplication between the alpha row vector $\\alpha$ and each column of the gram matrix $K$, computing the weighted sum of kernel evalutations for each training image. These images were shuffled before each training run, with the algorithm operate on a single example at a time, hence administering an online learning setting. If a mistake is made i.e. the predicted class label does not match the true class label, then the alpha value corresponding to the true class label increases and simulataneously, we decrease that of the predicted class label. This happens for each image, hence continuously adding or subtracting terms to the sum during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
